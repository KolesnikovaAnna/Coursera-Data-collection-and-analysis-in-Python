#!/usr/bin/env python
# coding: utf-8

# <center>
# <img src="logo.png" height="900"> 
# </center>
# 
# 
# #  Акции
# 
# В этом задании мы немного поработаем с ценами на акции. 

# In[1]:


import numpy as np
import pandas as pd

import scipy.stats as sts
import matplotlib.pyplot as plt
import seaborn as sns

plt.style.use('ggplot')  # стиль для графиков
get_ipython().run_line_magic('matplotlib', 'inline')


# В табличке `prices.tsv` лежат данные о том как менялась цена на акции из индексов [S&P-500](https://ru.wikipedia.org/wiki/S%26P_500), [NASDAQ-100](https://ru.wikipedia.org/wiki/Nasdaq-100) и [DJI](https://ru.wikipedia.org/wiki/Промышленный_индекс_Доу_—_Джонса) в течение последних $10$ лет. В табличке `information.tsv` лежит дополнительная полезная информация по каждой из ценных бумаг.  Подгрузим эти таблицы и посмотрим на них. 

# In[2]:


df_prices = pd.read_csv('price.tsv', sep='\t')

# сделали дату индексом таблицы и применили это преобразование
df_prices.set_index('Date', inplace=True)  
df_prices.head()


# In[3]:


df_inf = pd.read_csv('information.tsv', sep='\t')
df_inf.head()


# > Давайте решим пробную задачку, чтобы вы понимали, как устроена система тестирования. 
# 
# В колонках `'S&P-500', 'NASDAQ', 'DJI'` лежит True, если ценная бумага входит в соотвествующий индекс. Сколько ценных бумаг из таблицы входили в индекс NASDAQ? Запишите результат в пременную `n_nasdaq`.

# In[4]:


n_nasdaq = df_inf['NASDAQ'].sum() # каждое True это 1, а False 0
n_nasdaq


# Все ваши расчёты будут тестироваться с помощью вот таких тестов. 

# In[5]:


assert n_nasdaq == 103


# Мы положили в переменную `n_nasdaq` число ценных бумаг, как и требовалось в задании. Тесты прошли и всё успешно отработало. Подобные тесты сделаны по каждому заданию, но скрыты от вас. Вы довольно часто будете видеть ячейки с комментарием: 

# In[ ]:


# проверка, что задание решено корректно


# Он означает, что внутри этой ячейки есть секретные тесты, которые сами запустятся, когда нажмёте на кнопку __Submit assignment.__

# __а)__ Теперь настоящее задание. Сколько ценных бумаг входят во все три индекса сразу?

# In[9]:


### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz
# will the code be with you

# Формат ответа: целое число, пример: 7
n_sp = (df_inf['S&P-500']&df_inf['NASDAQ']&df_inf['DJI']).sum() # запишите результат в переменную n_sp 

# your code here
n_sp


# In[10]:


# проверка, что задание решено корректно
assert n_sp < 10

# Подобные тесты скрыты от вас


# __б)__ В колонке `Founded` записан год основания компании. Сколько компаний из индекса S&P-500 были основаны в 19 веке (1900 год относится к 20 веку)? 

# In[38]:


### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz
# will the code be with you

# Формат ответа: целое число, пример: 91
#n_founded = df_inf[df_inf['S&P-500']
n_founded = ((df_inf['Founded']>=1800)&(df_inf['Founded']<1900)).sum()
# запишите результат в переменную n_founded

# your code here
n_founded


# In[39]:


# проверка, что задание решено корректно
assert n_founded < 100
assert n_founded > 90

# Подобные тесты скрыты от вас


# __в)__  В колонке `GICS Sector` находится сектор экономики, в котором работает компания. Сколько всего уникальных секторов представлено в данных? Все пропуски в этой колонке удалите методом `.dropna()`. 

# In[47]:


### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz
# will the code be with you

# Формат ответа: целое число, пример: 10
n_sectors = len(df_inf['GICS Sector'].dropna().unique())

# your code here
n_sectors


# In[48]:


# проверка, что задание решено корректно
assert n_sectors > 5
assert n_sectors < 15

# Подобные тесты скрыты от вас


# __г)__ Сколько компаний из индекса S&P-500 в сумме приходится на $3$ самых крупных сектора? 

# In[54]:


### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz
# will the code be with you

# Формат ответа: целое число, пример: 205
sp = df_inf[df_inf['S&P-500']]
n_top3  = sp['GICS Sector'].value_counts()[:3].sum()
# запишите результат в переменную n_top3

# your code here
n_top3


# In[55]:


# проверка, что задание решено корректно
assert n_top3 < 300
assert n_top3 > 200

# Подобные тесты скрыты от вас


# __д)__ У скольки компаний тикер (краткое название из колонки `Symbol`) состоит из трёх букв? 

# In[92]:


### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz
# will the code be with you

# Формат ответа: целое число, пример: 322
#n_ticker  = re.findall(r'???', df_inf.Symbol.values)
n_ticker  = df_inf.Symbol.apply(lambda ticker: len(ticker))
# запишите результат в переменную n_ticker

# your code here
n_ticker = len(n_ticker[n_ticker==3])


# In[93]:


# проверка, что задание решено корректно
assert n_ticker > 300
assert n_ticker < 400

# Подобные тесты скрыты от вас


# А из другого количества букв? Заведите колонку `letter_count` с числом букв в тикере, а после подсчитайте как часто в ней встречаются разные значения. 

# In[98]:


### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz
# will the code be with you
df_inf['letter_count']  = df_inf.Symbol.apply(lambda ticker: len(ticker))

# your code here
df_inf.letter_count.value_counts()


# Создайте в таблице новую колонку `first_letter`. Запишите туда первую букву каждого тикера из колонки `Symbol`. Какая буква встречается на первом месте чаще всего? 

# In[101]:


### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz
# will the code be with you
df_inf['first_letter']  = df_inf.Symbol.apply(lambda ticker: ticker[0])
# Формат ответа: строка, пример: 'B'
popular_letter = df_inf.first_letter.value_counts().index[0]

# your code here
popular_letter


# In[ ]:


# проверка, что задание решено корректно
assert popular_letter not in {'T', 'C', 'M', 'P', 'D'}

# Подобные тесты скрыты от вас


# __е)__ Теперь поработаем со стоимостью акций. 
# 
# - Из таблицы `df_inf` возьмите колонку `Symbol` и сохраните значения из неё, `.values`, в вектор tickers
# - Выберите из вектора 10 случайных тикеров командой `np.random.choice`, опцию `replace` установить в `False`, нам нужна выборка без повторений

# In[131]:


### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz
# will the code be with you

# Формат ответа: целое число, пример: 505
tickers = df_inf.Symbol.values

# Формат ответа: массив из тикеров, пример: ['TSLA', 'AAPL', 'GOOG']
tickers10 = np.random.choice(tickers, 10, replace = False)

# your code here
tickers10


# In[132]:


# проверка, что задание решено корректно
assert tickers.size > 500
assert tickers.size < 550

# Подобные тесты скрыты от вас


# Методом `.plot` постройте для выбранных 10 тикеров картинку с динамикой их цен. В скобках у `.plot()` допишите `figsize=(12,7)`, чтобы отрегулировать размер картинки.

# In[152]:


### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz
# will the code be with you
# your code here
#plt.plot(df_prices[tickers10].index.values, tickers10, kind="line", figsize=(12,7))
#
df_prices[tickers10].plot(figsize=(12,7))


# Методом `.hist()` постройте для этих цен гистограммы. Выберите количество бинов `bins` равное $25$, опцию `density` поставьте в `True`. Это отнормирует высоту столбиков так, чтобы сумма площадей под ними была равна единице. 

# In[157]:


### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz
# will the code be with you

# your code here
df_prices[tickers10].hist(bins=25, density=True)


# - Как скорее всего распределена стоимость акций?
# - Что происходило с финансовыми рынками в течение последних $10$ лет? Они росли? Они падали? Видно ли, что были кризисы? 

# Финансовые продукты характеризуются двумя основными характеристикам – __доходностью__ и __риском.__ Доходность – это процентное изменение стоимости за некоторый промежуток времени. Мы будем работать с доходностями за день: 
# 
# $$
# R_t = \frac{P_t - P_{t-1}}{P_{t-1}}
# $$
# 
# Перейдите к доходностям для всей таблицы `df_prices`. Для того, чтобы посчитать разность между каждой строкой таблицы и предыдущей строкой, используйте команду `.diff()`. Чтобы сдвинуть все строки на одну вниз, используйте команду `shift(1)`.  
# 
# Поделите результат работы команды `diff` на результат работы команды `shift`. Обратите внимание, что в первой колонке теперь все значения `NaN`, так как мы не можем посчитать доходность для самого первого дня. Удалите из таблицы эту строку. 

# In[169]:


### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz
# will the code be with you

df_r = df_prices
dif= df_r.diff()
shif = df_r.shift(1)
# your code here
df_r = dif/shif

df_r = df_r.drop(index = '2010-08-02')
df_r


# In[170]:


# проверка, что задание решено корректно
assert df_r.iloc[0,0] < 1

# Подобные тесты скрыты от вас


# Методом `.plot` постройте для выбранных ранее 10  случайных тикеров картинку с динамикой доходностей. 

# In[171]:


### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz
# will the code be with you

# your code here
df_r[tickers10].plot(figsize=(12,7))


# Постройте для доходностей этих десяти тикеров гистограммы. 

# In[172]:


### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz
# will the code be with you

# your code here
df_r[tickers10].hist(bins=25, density=True)


# Постройте для доходностей этих 10 бумаг ящики с усами. Для этого в опциях команды `plot` укажите `'kind'='box'`. 

# In[173]:


### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz
# will the code be with you

# your code here
df_r[tickers10].plot(kind = 'box', figsize=(12,7))


# __Выводы:__ 
# 
# Доходности по нашим акциям имеют распределение похожее на нормальное, но есть отличие. По ящикам с усами видно, что в данных есть довольно большое количество выбросов. Это сигнализирует о том, что у распределения доходностей хвосты оказываются более тяжёлыми, чем у нормального распределения. То есть под ними сосредоточено больше вероятностной массы и из-за этого редкое события более вероятны, чем для нормального распределения. Такую особенность финансовых данных мы более подробно будем обсуждать в будущем. 
# 
# Кроме того, по построенным визуализациям видно, что средние доходности практически для всех ценных бумаг находится близко к нулю.

# __ё)__  Без буквы `ё` никуда, скажут нам [Пафнутий Чебышёв](https://ru.wikipedia.org/wiki/%D0%A7%D0%B5%D0%B1%D1%8B%D1%88%D1%91%D0%B2,_%D0%9F%D0%B0%D1%84%D0%BD%D1%83%D1%82%D0%B8%D0%B9_%D0%9B%D1%8C%D0%B2%D0%BE%D0%B2%D0%B8%D1%87) и [Лёв Толстой](https://arzamas.academy/special/ruslit/writers/tolstoy).  
# 
# Посчитайте для всех компаний среднюю доходность (просто сделайте `.mean()` за весь период). Найдите 10 самых доходных компаний и 10 самых убыточных. 

# In[202]:


### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz
# will the code be with you

R  =  df_r.mean()     # средние доходности 

# Формат ответа: массивы из 10 тикеров, отсортированных в ликсикографическом порядке 
# пример: ['CARR', 'DOCU', 'DXCM', 'HWM']
# тип данных должен быть list, не np.array
# метод .values выдаёт данные в формате np.array: array(['CARR', 'DOCU', 'DXCM', 'HWM'])
rtop_10 = list(R.sort_values(ascending=False)[:10].index)  # list из тикеров 10 самых доходных компаний отсортированный по алфавиту
#rbottom_10 = ...   # list из тикеров 10 самых убыточных компаний отсортированный по алфавиту

# your code here
rbottom_10 = list(R.sort_values(ascending=True)[:10].index)
rbottom_10


# In[203]:


# проверка, что задание решено корректно
assert 'DXCM' in rtop_10
assert 'HWM' in rtop_10

assert 'SLB' in rbottom_10
assert 'FOX' in rbottom_10

# Подобные тесты скрыты от вас


# Есть ли среди самых доходных компаний Тесла? :) 

# __ж)__ Мы поговорили о доходности. Теперь поговорим о риске. Один из способов измерить, насколько ценная бумага рискованная -  использовать стандартное отклонение. 
# 
# Посчитайте для всех компаний стандартное отклонение доходности. Найдите 10 самых рискованных компаний и 10 самых безрисковых. 

# In[ ]:


### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz
# will the code be with you

STD  = ...           # стандартные отклонения доходностей

# Формат ответа: массивы из 10 тикеров, отсортированных в ликсикографическом порядке 
# пример: ['CARR', 'DOCU', 'DXCM', 'HWM']
# тип данных должен быть list, не np.array
# метод .values выдаёт данные в формате np.array: array(['CARR', 'DOCU', 'DXCM', 'HWM'])
stdtop_10 = ...      # list из тикеров 10 самых доходных компаний отсортированный по алфавиту
stdbottom_10 = ...   # list из тикеров 10 самых убыточных компаний отсортированный по алфавиту

# your code here


# In[ ]:


# проверка, что задание решено корректно
assert 'TSLA' in stdtop_10
assert 'HWM' in stdtop_10

assert 'PEP' in stdbottom_10
assert 'DUK' in stdbottom_10

# Подобные тесты скрыты от вас


# Есть ли среди самых рискованных компаний Тесла? :) 

# Обычно инвесторы принимают решение покупать бумагу к себе в портфель, отталкиваясь от того какие соотношения доходность/риск существуют на рынке. Построим для наших ценных бумаг диаграмму рассеивания, на которой будет видно где по своей доходности и риску находится какая ценная бумага. 
# 
# Если вы корректно решили все предыдущие пункты, вам достаточно просто запустить код ниже и он выполнится сам. 

# In[ ]:


# таблица с доходностями и риском
data = pd.DataFrame({'std': STD, 'r': R})

# добавили сектора экономики для каждой из ценных бумаг
data = data.join(df_inf.set_index('Symbol')['GICS Sector'])
data.fillna('another sector')
data.head()


# In[ ]:


plt.figure(figsize=(15, 8))

sns.scatterplot(data=data, x='std', y='r', hue='GICS Sector')

tsla = data.loc['TSLA']
sns.regplot([tsla['std']], [tsla['r']], scatter=True, fit_reg=False, 
            marker='x', color='black', scatter_kws={'s':100}) 

plt.ylim(-0.002, 0.005)
plt.xlim(0.01, 0.04)

plt.xlabel('Риск')
plt.ylabel('Доходность')
plt.title('Риск и доходность различных ценных бумаг');


# Чем больше риск, тем выше потенциально может оказаться доходноcть. __Но при этом мы с более высокой вероятностью можем уйти в убыток.__ Чёрным крестиком отдельно отмечена Тесла, которая обладает довольно высокими доходностью и риском.
# 
# > Можно ли купить какую-то другую бумагу, которая обладает примерно такой же доходностью как тесла, но при этом её риск меньше? 
# 
# Сделайте группировку (`groupby`) для таблицы `data` по секторам экономики. Какой из секторов экономики обладает самым низким медианным значением риска? 

# In[ ]:


### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz
# will the code be with you

df_agg = ...      # таблица после группировки 

# Формат ответа: строка, пример: 'Utilities'
min_sector = ...  # название сектора с минимальным медианным риском
max_sector = ...  # название сектора с максимальной доходностью 

# your code here


# In[ ]:


# проверка, что задание решено корректно
assert min_sector == 'Utilities'

# Подобные тесты скрыты от вас


# __з)__  Надо понимать, что стандартное отклонение чувствительно к выбросам. Поэтому в качестве меры риска часто рассматривают VaR. 
# 
# __Value-at-Risk__ — одна из самых распространенных форм измерения финансовых рисков. Общепринято обозначается $VaR$.
# Еще его часто называют статистика $16:15$, такое название он получил потому, что $16:15$ – это время, в которое он якобы должен лежать на столе главы правления банка JPMorgan. (В этом банке данный показатель был впервые введен с целью повышения эффективности работы с рисками).
# 
# __Value-at-Risk__ на каком-либо уровне (скажем, $5\%$) – это просто квантиль на уровне $5\%$. То есть это такая доходность, что в $95\%$ случаев у нас дела будут лучше.

# Посчитайте $5\%$ VaR по всем ценным бумагам. Для этого используйте метод `quantile()`. Найдите 10 самых рискованных компаний и 10 наименее рискованных компаний с точки зрения этого показателя. Не забудьте умножить результаты на $-1$ перед сортировкой. 

# In[ ]:


### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz
# will the code be with you

VaR  = ...           # Value at risk по нашим бумагам

# Формат ответа: массивы из 10 тикеров, отсортированных в ликсикографическом порядке 
# пример: ['CARR', 'DOCU', 'DXCM', 'HWM']
# тип данных должен быть list, не np.array
# метод .values выдаёт данные в формате np.array: array(['CARR', 'DOCU', 'DXCM', 'HWM'])
VaRtop_10 = ...      # list из тикеров 10 самых рисковых компаний отсортированный по алфавиту
VaRbottom_10 = ...   # list из тикеров 10 самых безрисковых компаний отсортированный по алфавиту

# your code here


# In[ ]:


# проверка, что задание решено корректно
assert 'TSLA' in VaRtop_10 
assert 'HWM' in VaRtop_10 

assert 'PG' in VaRbottom_10
assert 'MCD' in VaRbottom_10

# Подобные тесты скрыты от вас


# $VaR$ хорош тем, что описывает именно ту часть распределения, которую мы боимся. Но $VaR$ - это лучшее из $5\%$ худших случаев. А что лежит в тех $5\%$?…

# __и)__  __Expected shortfall__ - это среднее значение по всем тем точкам, что оказались хуже $VaR$, То есть среднее по худшим $5\%$. Эта метрика показывает что в среднем произойдёт с нашей доходностью в этих самых плохих $5\%$ случаев. 
# 
# - Рассчитаете $ES$ для Теслы
# - Предположим, что мы вложили в Теслу $1000$ долларов в один из самых неудачных дней. Сколько в среднем денег мы потеряем от этой $1000$ долларов к концу дня? 
# - Сколько денег мы заработаем в $5\%$ лучших случаем к концу дня? 
# 
# __Важно:__ VaR и Es в этом пункте - отрицательные числа.

# In[ ]:


### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz
# will the code be with you

# Формат ответа: действительное число, пример: 0.073254
var_tsla = ...   # VaR для Теслы
es_tsla  = ...   # ES для теслы 
loss = ...       # Потеря от 1000$
profit = ...     # Заработок от 1000$

# your code here


# In[ ]:


# проверка, что задание решено корректно
assert np.abs(es_tsla + 0.073254619) < 1e-5

# Подобные тесты скрыты от вас


# ## Какая метрика лучше? 
# 
# Никакая. Все рассуждения о риске – это попытки уложить функцию распределения доходностей в одно единственное число. Поэтому информация потеряется и все метрики будут не идеальны. А к чему это приведет, можно прочитать в книге Скотта Паттерсона "Кванты. Как волшебники от математики заработали миллиарды и чуть не обрушили фондовый рынок." 
# 
# Тем не менее, какие-то цифры, на которые можно было бы ориентироваться при принятии решений необходимы. Из-за этого методы оценки риска продвинулись довольно сильно вперёд и ещё появятся в будущих домашних заданиях нашего курса. 

# <center>
# <img src="memes01.png" width="500"> 
# </center>
